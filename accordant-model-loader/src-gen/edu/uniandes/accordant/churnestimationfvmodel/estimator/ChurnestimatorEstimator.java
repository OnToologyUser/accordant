/*
 * generated by Accordant
 */

package edu.uniandes.accordant.churnestimationfvmodel.estimator;

import java.io.InputStream;
import java.net.URL;
import java.util.ArrayList;
import java.util.List;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.ml.Transformer;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;
import org.jpmml.evaluator.Evaluator;
import org.jpmml.evaluator.EvaluatorBuilder;
import org.jpmml.evaluator.LoadingModelEvaluatorBuilder;
import org.jpmml.evaluator.spark.TransformerBuilder;

public class ChurnestimatorEstimator {

	public static void main(String[] args) throws Exception {

		//TODO add master params code from dv
		SparkConf conf = new SparkConf().setAppName("ChurnestimatorEstimator")
						.setMaster("local[*]");
		
		JavaSparkContext sc = new JavaSparkContext(conf);
		SparkSession sparkSession = new SparkSession(sc.sc());
		InputStream pmmlFile = new URL("https://s3.amazonaws.com/ccastellanos87.bda.workshop.io/data/ChurnDTree-v2.pmml.xml")
						.openStream();
		EvaluatorBuilder evaluatorBuilder = new LoadingModelEvaluatorBuilder().load(pmmlFile);
		
		Evaluator evaluator = evaluatorBuilder.build();
		evaluator.verify();
		TransformerBuilder pmmlTransformerBuilder = new TransformerBuilder(evaluator)
						.withTargetCols().exploded(true);
		List<StructField> fields = new ArrayList<StructField>();
		
		fields.add(DataTypes.createStructField("VMailMessage", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("DayMins", DataTypes.DoubleType, true));
		fields.add(DataTypes.createStructField("EveMins", DataTypes.DoubleType, true));
		fields.add(DataTypes.createStructField("NightMins", DataTypes.DoubleType, true));
		fields.add(DataTypes.createStructField("IntlMins", DataTypes.DoubleType, true));
		fields.add(DataTypes.createStructField("CustServCalls", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("DayCalls", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("DayCharge", DataTypes.DoubleType, true));
		fields.add(DataTypes.createStructField("EveCalls", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("EveCharge", DataTypes.DoubleType, true));
		fields.add(DataTypes.createStructField("NightCalls", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("NightCharge", DataTypes.DoubleType, true));
		fields.add(DataTypes.createStructField("IntlCalls", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("IntlCharge", DataTypes.DoubleType, true));
		fields.add(DataTypes.createStructField("AreaCode", DataTypes.StringType, true));
		fields.add(DataTypes.createStructField("Phone", DataTypes.StringType, true));
		fields.add(DataTypes.createStructField("AccountLength", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("Churn", DataTypes.StringType, true));
		fields.add(DataTypes.createStructField("IntlPlan", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("VMailPlan", DataTypes.IntegerType, true));
		fields.add(DataTypes.createStructField("State", DataTypes.StringType, true));
		StructType schema = DataTypes.createStructType(fields);
		Transformer pmmlTransformer = pmmlTransformerBuilder.build();
		
		//TODO add input connector code
		Dataset<Row> inputDs = sparkSession.read().schema(schema).csv("src/main/resources/nmac_JFK2_predictors.csv");
		
		Dataset<Row> resultDs = pmmlTransformer.transform(inputDs);
		
		//TODO add output connector code
		//log(LATENCY,0.0,2.0,SECONDS);
		resultDs.coalesce(1).write().option("header", "true").mode("overwrite")
										.csv("out/Churnestimator.csv");
										
		sparkSession.close();
		sc.close();
	}
}		
